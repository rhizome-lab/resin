//! Image-based fields for texture sampling.
//!
//! Provides `ImageField` which loads an image and exposes it as a `Field<Vec2, Color>`.
//!
//! # Example
//!
//! ```ignore
//! use rhizome_resin_image::{ImageField, WrapMode, FilterMode};
//! use rhizome_resin_field::{Field, EvalContext};
//! use glam::Vec2;
//!
//! let field = ImageField::from_file("texture.png")?;
//! let ctx = EvalContext::new();
//!
//! // Sample at UV coordinates (0.5, 0.5)
//! let color = field.sample(Vec2::new(0.5, 0.5), &ctx);
//! ```

use std::io::Read;
use std::path::Path;

use glam::{Vec2, Vec4};
use image::{DynamicImage, GenericImageView, ImageError};

use rhizome_resin_color::Rgba;
use rhizome_resin_field::{EvalContext, Field};

/// How to handle UV coordinates outside [0, 1].
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum WrapMode {
    /// Repeat the texture (fract of coordinate).
    #[default]
    Repeat,
    /// Clamp coordinates to [0, 1].
    Clamp,
    /// Mirror the texture at boundaries.
    Mirror,
}

/// How to sample between pixels.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum FilterMode {
    /// Use the nearest pixel (blocky).
    Nearest,
    /// Bilinear interpolation (smooth).
    #[default]
    Bilinear,
}

/// An image that can be sampled as a field.
///
/// UV coordinates go from (0, 0) at the top-left to (1, 1) at the bottom-right.
#[derive(Clone)]
pub struct ImageField {
    /// Image pixel data as RGBA.
    data: Vec<[f32; 4]>,
    /// Image width in pixels.
    width: u32,
    /// Image height in pixels.
    height: u32,
    /// How to handle coordinates outside [0, 1].
    pub wrap_mode: WrapMode,
    /// How to interpolate between pixels.
    pub filter_mode: FilterMode,
}

impl std::fmt::Debug for ImageField {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("ImageField")
            .field("width", &self.width)
            .field("height", &self.height)
            .field("wrap_mode", &self.wrap_mode)
            .field("filter_mode", &self.filter_mode)
            .finish()
    }
}

/// Errors that can occur when loading images.
#[derive(Debug)]
pub enum ImageFieldError {
    /// Failed to load the image file.
    ImageError(ImageError),
    /// I/O error reading the file.
    IoError(std::io::Error),
}

impl std::fmt::Display for ImageFieldError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ImageFieldError::ImageError(e) => write!(f, "Image error: {}", e),
            ImageFieldError::IoError(e) => write!(f, "IO error: {}", e),
        }
    }
}

impl std::error::Error for ImageFieldError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match self {
            ImageFieldError::ImageError(e) => Some(e),
            ImageFieldError::IoError(e) => Some(e),
        }
    }
}

impl From<ImageError> for ImageFieldError {
    fn from(e: ImageError) -> Self {
        ImageFieldError::ImageError(e)
    }
}

impl From<std::io::Error> for ImageFieldError {
    fn from(e: std::io::Error) -> Self {
        ImageFieldError::IoError(e)
    }
}

impl ImageField {
    /// Creates an image field from a file path.
    pub fn from_file<P: AsRef<Path>>(path: P) -> Result<Self, ImageFieldError> {
        let img = image::open(path)?;
        Ok(Self::from_image(img))
    }

    /// Creates an image field from raw bytes.
    pub fn from_bytes(bytes: &[u8]) -> Result<Self, ImageFieldError> {
        let img = image::load_from_memory(bytes)?;
        Ok(Self::from_image(img))
    }

    /// Creates an image field from a reader.
    pub fn from_reader<R: Read + std::io::BufRead + std::io::Seek>(
        reader: R,
    ) -> Result<Self, ImageFieldError> {
        let img = image::ImageReader::new(reader)
            .with_guessed_format()?
            .decode()?;
        Ok(Self::from_image(img))
    }

    /// Creates an image field from a DynamicImage.
    pub fn from_image(img: DynamicImage) -> Self {
        let (width, height) = img.dimensions();
        let rgba = img.to_rgba8();

        // Convert to f32 RGBA
        let data: Vec<[f32; 4]> = rgba
            .pixels()
            .map(|p| {
                [
                    p.0[0] as f32 / 255.0,
                    p.0[1] as f32 / 255.0,
                    p.0[2] as f32 / 255.0,
                    p.0[3] as f32 / 255.0,
                ]
            })
            .collect();

        Self {
            data,
            width,
            height,
            wrap_mode: WrapMode::default(),
            filter_mode: FilterMode::default(),
        }
    }

    /// Creates a solid color image field.
    pub fn solid(color: Rgba) -> Self {
        Self {
            data: vec![[color.r, color.g, color.b, color.a]],
            width: 1,
            height: 1,
            wrap_mode: WrapMode::Repeat,
            filter_mode: FilterMode::Nearest,
        }
    }

    /// Creates an image field from raw pixel data.
    ///
    /// `data` should be in row-major order, RGBA format, with values in [0, 1].
    pub fn from_raw(data: Vec<[f32; 4]>, width: u32, height: u32) -> Self {
        assert_eq!(
            data.len(),
            (width * height) as usize,
            "Data length must match width * height"
        );
        Self {
            data,
            width,
            height,
            wrap_mode: WrapMode::default(),
            filter_mode: FilterMode::default(),
        }
    }

    /// Sets the wrap mode for this image field.
    pub fn with_wrap_mode(mut self, mode: WrapMode) -> Self {
        self.wrap_mode = mode;
        self
    }

    /// Sets the filter mode for this image field.
    pub fn with_filter_mode(mut self, mode: FilterMode) -> Self {
        self.filter_mode = mode;
        self
    }

    /// Returns the image dimensions.
    pub fn dimensions(&self) -> (u32, u32) {
        (self.width, self.height)
    }

    /// Wraps a coordinate according to the wrap mode.
    fn wrap(&self, mut t: f32) -> f32 {
        match self.wrap_mode {
            WrapMode::Repeat => {
                t = t.rem_euclid(1.0);
                if t < 0.0 { t + 1.0 } else { t }
            }
            WrapMode::Clamp => t.clamp(0.0, 1.0),
            WrapMode::Mirror => {
                t = t.rem_euclid(2.0);
                if t > 1.0 { 2.0 - t } else { t }
            }
        }
    }

    /// Gets a pixel at integer coordinates (clamped to bounds).
    pub fn get_pixel(&self, x: u32, y: u32) -> [f32; 4] {
        let x = x.min(self.width - 1);
        let y = y.min(self.height - 1);
        let idx = (y * self.width + x) as usize;
        self.data[idx]
    }

    /// Samples the image at normalized UV coordinates.
    pub fn sample_uv(&self, u: f32, v: f32) -> Rgba {
        let u = self.wrap(u);
        let v = self.wrap(v);

        match self.filter_mode {
            FilterMode::Nearest => {
                let x = (u * self.width as f32).floor() as u32;
                let y = (v * self.height as f32).floor() as u32;
                let pixel = self.get_pixel(x, y);
                Rgba::new(pixel[0], pixel[1], pixel[2], pixel[3])
            }
            FilterMode::Bilinear => {
                // Map to pixel coordinates
                let px = u * self.width as f32 - 0.5;
                let py = v * self.height as f32 - 0.5;

                let x0 = px.floor() as i32;
                let y0 = py.floor() as i32;
                let fx = px - px.floor();
                let fy = py - py.floor();

                // Get four surrounding pixels (with wrapping)
                let x0u = x0.rem_euclid(self.width as i32) as u32;
                let x1u = (x0 + 1).rem_euclid(self.width as i32) as u32;
                let y0u = y0.rem_euclid(self.height as i32) as u32;
                let y1u = (y0 + 1).rem_euclid(self.height as i32) as u32;

                let p00 = self.get_pixel(x0u, y0u);
                let p10 = self.get_pixel(x1u, y0u);
                let p01 = self.get_pixel(x0u, y1u);
                let p11 = self.get_pixel(x1u, y1u);

                // Bilinear interpolation
                let lerp = |a: f32, b: f32, t: f32| a + (b - a) * t;
                let lerp_pixel = |a: [f32; 4], b: [f32; 4], t: f32| {
                    [
                        lerp(a[0], b[0], t),
                        lerp(a[1], b[1], t),
                        lerp(a[2], b[2], t),
                        lerp(a[3], b[3], t),
                    ]
                };

                let top = lerp_pixel(p00, p10, fx);
                let bottom = lerp_pixel(p01, p11, fx);
                let result = lerp_pixel(top, bottom, fy);

                Rgba::new(result[0], result[1], result[2], result[3])
            }
        }
    }

    /// Samples the image and returns a Vec4 (useful for RGBA operations).
    pub fn sample_vec4(&self, u: f32, v: f32) -> Vec4 {
        let color = self.sample_uv(u, v);
        Vec4::new(color.r, color.g, color.b, color.a)
    }
}

impl Field<Vec2, Rgba> for ImageField {
    fn sample(&self, input: Vec2, _ctx: &EvalContext) -> Rgba {
        self.sample_uv(input.x, input.y)
    }
}

impl Field<Vec2, Vec4> for ImageField {
    fn sample(&self, input: Vec2, _ctx: &EvalContext) -> Vec4 {
        self.sample_vec4(input.x, input.y)
    }
}

impl Field<Vec2, f32> for ImageField {
    /// Samples the image as grayscale (luminance).
    fn sample(&self, input: Vec2, _ctx: &EvalContext) -> f32 {
        let color = self.sample_uv(input.x, input.y);
        // Standard luminance coefficients (ITU-R BT.709)
        0.2126 * color.r + 0.7152 * color.g + 0.0722 * color.b
    }
}

// ============================================================================
// Texture baking - render Field to Image
// ============================================================================

/// Configuration for texture baking.
#[derive(Debug, Clone)]
pub struct BakeConfig {
    /// Output width in pixels.
    pub width: u32,
    /// Output height in pixels.
    pub height: u32,
    /// Number of samples per pixel for anti-aliasing (1 = no AA).
    pub samples: u32,
}

impl Default for BakeConfig {
    fn default() -> Self {
        Self {
            width: 256,
            height: 256,
            samples: 1,
        }
    }
}

impl BakeConfig {
    /// Creates a new bake config with the given dimensions.
    pub fn new(width: u32, height: u32) -> Self {
        Self {
            width,
            height,
            samples: 1,
        }
    }

    /// Sets the number of anti-aliasing samples per pixel.
    pub fn with_samples(mut self, samples: u32) -> Self {
        self.samples = samples.max(1);
        self
    }
}

/// Bakes a scalar field (Field<Vec2, f32>) to a grayscale image.
///
/// UV coordinates go from (0, 0) at top-left to (1, 1) at bottom-right.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{bake_scalar, BakeConfig};
/// use rhizome_resin_field::{Perlin2D, Field, EvalContext};
///
/// let noise = Perlin2D::new().scale(4.0);
/// let config = BakeConfig::new(256, 256);
/// let ctx = EvalContext::new();
///
/// let image = bake_scalar(&noise, &config, &ctx);
/// assert_eq!(image.dimensions(), (256, 256));
/// ```
pub fn bake_scalar<F: Field<Vec2, f32>>(
    field: &F,
    config: &BakeConfig,
    ctx: &EvalContext,
) -> ImageField {
    let mut data = Vec::with_capacity((config.width * config.height) as usize);

    for y in 0..config.height {
        for x in 0..config.width {
            let value = if config.samples == 1 {
                // Single sample at pixel center
                let u = (x as f32 + 0.5) / config.width as f32;
                let v = (y as f32 + 0.5) / config.height as f32;
                field.sample(Vec2::new(u, v), ctx)
            } else {
                // Multi-sample anti-aliasing
                let mut sum = 0.0;
                let samples_sqrt = (config.samples as f32).sqrt().ceil() as u32;
                let actual_samples = samples_sqrt * samples_sqrt;

                for sy in 0..samples_sqrt {
                    for sx in 0..samples_sqrt {
                        let u = (x as f32 + (sx as f32 + 0.5) / samples_sqrt as f32)
                            / config.width as f32;
                        let v = (y as f32 + (sy as f32 + 0.5) / samples_sqrt as f32)
                            / config.height as f32;
                        sum += field.sample(Vec2::new(u, v), ctx);
                    }
                }
                sum / actual_samples as f32
            };

            let clamped = value.clamp(0.0, 1.0);
            data.push([clamped, clamped, clamped, 1.0]);
        }
    }

    ImageField::from_raw(data, config.width, config.height)
}

/// Bakes an RGBA field (Field<Vec2, Rgba>) to an image.
///
/// # Example
///
/// ```ignore
/// use rhizome_resin_image::{bake_rgba, BakeConfig};
/// use rhizome_resin_field::{Field, EvalContext};
///
/// let field = MyColorField::new();
/// let config = BakeConfig::new(512, 512);
/// let ctx = EvalContext::new();
///
/// let image = bake_rgba(&field, &config, &ctx);
/// ```
pub fn bake_rgba<F: Field<Vec2, Rgba>>(
    field: &F,
    config: &BakeConfig,
    ctx: &EvalContext,
) -> ImageField {
    let mut data = Vec::with_capacity((config.width * config.height) as usize);

    for y in 0..config.height {
        for x in 0..config.width {
            let color = if config.samples == 1 {
                let u = (x as f32 + 0.5) / config.width as f32;
                let v = (y as f32 + 0.5) / config.height as f32;
                field.sample(Vec2::new(u, v), ctx)
            } else {
                let mut sum = Rgba::new(0.0, 0.0, 0.0, 0.0);
                let samples_sqrt = (config.samples as f32).sqrt().ceil() as u32;
                let actual_samples = samples_sqrt * samples_sqrt;

                for sy in 0..samples_sqrt {
                    for sx in 0..samples_sqrt {
                        let u = (x as f32 + (sx as f32 + 0.5) / samples_sqrt as f32)
                            / config.width as f32;
                        let v = (y as f32 + (sy as f32 + 0.5) / samples_sqrt as f32)
                            / config.height as f32;
                        let c = field.sample(Vec2::new(u, v), ctx);
                        sum.r += c.r;
                        sum.g += c.g;
                        sum.b += c.b;
                        sum.a += c.a;
                    }
                }
                let n = actual_samples as f32;
                Rgba::new(sum.r / n, sum.g / n, sum.b / n, sum.a / n)
            };

            data.push([
                color.r.clamp(0.0, 1.0),
                color.g.clamp(0.0, 1.0),
                color.b.clamp(0.0, 1.0),
                color.a.clamp(0.0, 1.0),
            ]);
        }
    }

    ImageField::from_raw(data, config.width, config.height)
}

/// Bakes a Vec4 field (Field<Vec2, Vec4>) to an image.
pub fn bake_vec4<F: Field<Vec2, Vec4>>(
    field: &F,
    config: &BakeConfig,
    ctx: &EvalContext,
) -> ImageField {
    let mut data = Vec::with_capacity((config.width * config.height) as usize);

    for y in 0..config.height {
        for x in 0..config.width {
            let color = if config.samples == 1 {
                let u = (x as f32 + 0.5) / config.width as f32;
                let v = (y as f32 + 0.5) / config.height as f32;
                field.sample(Vec2::new(u, v), ctx)
            } else {
                let mut sum = Vec4::ZERO;
                let samples_sqrt = (config.samples as f32).sqrt().ceil() as u32;
                let actual_samples = samples_sqrt * samples_sqrt;

                for sy in 0..samples_sqrt {
                    for sx in 0..samples_sqrt {
                        let u = (x as f32 + (sx as f32 + 0.5) / samples_sqrt as f32)
                            / config.width as f32;
                        let v = (y as f32 + (sy as f32 + 0.5) / samples_sqrt as f32)
                            / config.height as f32;
                        sum += field.sample(Vec2::new(u, v), ctx);
                    }
                }
                sum / actual_samples as f32
            };

            data.push([
                color.x.clamp(0.0, 1.0),
                color.y.clamp(0.0, 1.0),
                color.z.clamp(0.0, 1.0),
                color.w.clamp(0.0, 1.0),
            ]);
        }
    }

    ImageField::from_raw(data, config.width, config.height)
}

/// Exports an ImageField to a PNG file.
///
/// # Example
///
/// ```ignore
/// use rhizome_resin_image::{bake_scalar, BakeConfig, export_png};
/// use rhizome_resin_field::{Perlin2D, EvalContext};
///
/// let noise = Perlin2D::new().scale(4.0);
/// let config = BakeConfig::new(256, 256);
/// let ctx = EvalContext::new();
///
/// let image = bake_scalar(&noise, &config, &ctx);
/// export_png(&image, "noise.png").unwrap();
/// ```
pub fn export_png<P: AsRef<Path>>(image: &ImageField, path: P) -> Result<(), ImageFieldError> {
    let (width, height) = image.dimensions();
    let mut img_buf = image::RgbaImage::new(width, height);

    for y in 0..height {
        for x in 0..width {
            let u = (x as f32 + 0.5) / width as f32;
            let v = (y as f32 + 0.5) / height as f32;
            let color = image.sample_uv(u, v);

            img_buf.put_pixel(
                x,
                y,
                image::Rgba([
                    (color.r * 255.0) as u8,
                    (color.g * 255.0) as u8,
                    (color.b * 255.0) as u8,
                    (color.a * 255.0) as u8,
                ]),
            );
        }
    }

    img_buf.save(path)?;
    Ok(())
}

// ============================================================================
// Animation export - image sequences and GIF
// ============================================================================

/// Configuration for animation rendering.
#[derive(Debug, Clone)]
pub struct AnimationConfig {
    /// Output width in pixels.
    pub width: u32,
    /// Output height in pixels.
    pub height: u32,
    /// Number of frames.
    pub num_frames: usize,
    /// Frame duration in seconds.
    pub frame_duration: f32,
    /// Anti-aliasing samples (1 = no AA).
    pub samples: u32,
}

impl Default for AnimationConfig {
    fn default() -> Self {
        Self {
            width: 256,
            height: 256,
            num_frames: 60,
            frame_duration: 1.0 / 30.0,
            samples: 1,
        }
    }
}

impl AnimationConfig {
    /// Creates a new animation config.
    pub fn new(width: u32, height: u32, num_frames: usize) -> Self {
        Self {
            width,
            height,
            num_frames,
            ..Default::default()
        }
    }

    /// Sets the frame rate.
    pub fn with_fps(mut self, fps: f32) -> Self {
        self.frame_duration = 1.0 / fps;
        self
    }

    /// Sets the anti-aliasing samples.
    pub fn with_samples(mut self, samples: u32) -> Self {
        self.samples = samples.max(1);
        self
    }

    /// Returns the total animation duration in seconds.
    pub fn duration(&self) -> f32 {
        self.num_frames as f32 * self.frame_duration
    }
}

/// Renders an animation from a time-varying field to a sequence of images.
///
/// The field receives a Vec3 where xy are UV coordinates and z is time (0 to duration).
///
/// # Example
///
/// ```ignore
/// use rhizome_resin_image::{render_animation, AnimationConfig};
///
/// let config = AnimationConfig::new(256, 256, 60).with_fps(30.0);
/// let frames = render_animation(&my_field, &config);
/// ```
pub fn render_animation<F: Field<glam::Vec3, Rgba>>(
    field: &F,
    config: &AnimationConfig,
) -> Vec<ImageField> {
    let ctx = EvalContext::new();
    let bake_config = BakeConfig {
        width: config.width,
        height: config.height,
        samples: config.samples,
    };

    (0..config.num_frames)
        .map(|frame| {
            let t = frame as f32 * config.frame_duration;

            // Create a wrapper field that adds time to the input
            let frame_field = TimeSliceField {
                inner: field,
                time: t,
            };

            bake_rgba(&frame_field, &bake_config, &ctx)
        })
        .collect()
}

/// Helper struct to slice a 3D field at a specific time.
struct TimeSliceField<'a, F> {
    inner: &'a F,
    time: f32,
}

impl<'a, F: Field<glam::Vec3, Rgba>> Field<Vec2, Rgba> for TimeSliceField<'a, F> {
    fn sample(&self, input: Vec2, ctx: &EvalContext) -> Rgba {
        self.inner
            .sample(glam::Vec3::new(input.x, input.y, self.time), ctx)
    }
}

/// Exports animation frames as a numbered image sequence.
///
/// Files are named `{prefix}_{frame:04}.png`.
pub fn export_image_sequence<P: AsRef<Path>>(
    frames: &[ImageField],
    directory: P,
    prefix: &str,
) -> Result<(), ImageFieldError> {
    let dir = directory.as_ref();
    std::fs::create_dir_all(dir)?;

    for (i, frame) in frames.iter().enumerate() {
        let filename = format!("{}_{:04}.png", prefix, i);
        let path = dir.join(filename);
        export_png(frame, path)?;
    }

    Ok(())
}

/// Exports animation frames as an animated GIF.
///
/// # Arguments
/// * `frames` - The frames to export
/// * `path` - Output file path
/// * `frame_delay_ms` - Delay between frames in milliseconds
pub fn export_gif<P: AsRef<Path>>(
    frames: &[ImageField],
    path: P,
    frame_delay_ms: u16,
) -> Result<(), ImageFieldError> {
    use image::codecs::gif::{GifEncoder, Repeat};
    use image::{Delay, Frame};
    use std::fs::File;

    if frames.is_empty() {
        return Ok(());
    }

    let file = File::create(path)?;
    let mut encoder = GifEncoder::new(file);
    encoder.set_repeat(Repeat::Infinite)?;

    for img_field in frames {
        let (width, height) = img_field.dimensions();
        let mut rgba_buf = image::RgbaImage::new(width, height);

        for y in 0..height {
            for x in 0..width {
                let u = (x as f32 + 0.5) / width as f32;
                let v = (y as f32 + 0.5) / height as f32;
                let color = img_field.sample_uv(u, v);

                rgba_buf.put_pixel(
                    x,
                    y,
                    image::Rgba([
                        (color.r * 255.0) as u8,
                        (color.g * 255.0) as u8,
                        (color.b * 255.0) as u8,
                        (color.a * 255.0) as u8,
                    ]),
                );
            }
        }

        let delay = Delay::from_numer_denom_ms(frame_delay_ms as u32, 1);
        let frame = Frame::from_parts(rgba_buf, 0, 0, delay);
        encoder.encode_frame(frame)?;
    }

    Ok(())
}

/// Renders a scalar field animation (grayscale).
pub fn render_animation_scalar<F: Field<glam::Vec3, f32>>(
    field: &F,
    config: &AnimationConfig,
) -> Vec<ImageField> {
    let ctx = EvalContext::new();
    let bake_config = BakeConfig {
        width: config.width,
        height: config.height,
        samples: config.samples,
    };

    (0..config.num_frames)
        .map(|frame| {
            let t = frame as f32 * config.frame_duration;

            let frame_field = TimeSliceFieldScalar {
                inner: field,
                time: t,
            };

            bake_scalar(&frame_field, &bake_config, &ctx)
        })
        .collect()
}

struct TimeSliceFieldScalar<'a, F> {
    inner: &'a F,
    time: f32,
}

impl<'a, F: Field<glam::Vec3, f32>> Field<Vec2, f32> for TimeSliceFieldScalar<'a, F> {
    fn sample(&self, input: Vec2, ctx: &EvalContext) -> f32 {
        self.inner
            .sample(glam::Vec3::new(input.x, input.y, self.time), ctx)
    }
}

// ============================================================================
// Convolution filters
// ============================================================================

/// A convolution kernel for image filtering.
///
/// Kernels are square matrices of odd dimensions (3x3, 5x5, etc.).
#[derive(Debug, Clone)]
pub struct Kernel {
    /// Kernel weights in row-major order.
    pub weights: Vec<f32>,
    /// Kernel size (width and height).
    pub size: usize,
}

impl Kernel {
    /// Creates a new kernel from weights.
    ///
    /// The weights array must have length `size * size`.
    pub fn new(weights: Vec<f32>, size: usize) -> Self {
        assert_eq!(
            weights.len(),
            size * size,
            "Kernel weights must be sizeÃ—size"
        );
        assert!(size % 2 == 1, "Kernel size must be odd");
        Self { weights, size }
    }

    /// Creates a 3x3 identity kernel (no change).
    pub fn identity() -> Self {
        Self::new(vec![0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 3)
    }

    /// Creates a 3x3 box blur kernel.
    pub fn box_blur() -> Self {
        let w = 1.0 / 9.0;
        Self::new(vec![w, w, w, w, w, w, w, w, w], 3)
    }

    /// Creates a 3x3 Gaussian blur kernel.
    pub fn gaussian_blur_3x3() -> Self {
        let weights = vec![
            1.0 / 16.0,
            2.0 / 16.0,
            1.0 / 16.0,
            2.0 / 16.0,
            4.0 / 16.0,
            2.0 / 16.0,
            1.0 / 16.0,
            2.0 / 16.0,
            1.0 / 16.0,
        ];
        Self::new(weights, 3)
    }

    /// Creates a 5x5 Gaussian blur kernel.
    pub fn gaussian_blur_5x5() -> Self {
        let weights = vec![
            1.0, 4.0, 6.0, 4.0, 1.0, 4.0, 16.0, 24.0, 16.0, 4.0, 6.0, 24.0, 36.0, 24.0, 6.0, 4.0,
            16.0, 24.0, 16.0, 4.0, 1.0, 4.0, 6.0, 4.0, 1.0,
        ]
        .iter()
        .map(|&x| x / 256.0)
        .collect();
        Self::new(weights, 5)
    }

    /// Creates a 3x3 sharpen kernel.
    pub fn sharpen() -> Self {
        Self::new(vec![0.0, -1.0, 0.0, -1.0, 5.0, -1.0, 0.0, -1.0, 0.0], 3)
    }

    /// Creates a 3x3 unsharp mask kernel.
    pub fn unsharp_mask() -> Self {
        Self::new(
            vec![
                -1.0 / 9.0,
                -1.0 / 9.0,
                -1.0 / 9.0,
                -1.0 / 9.0,
                17.0 / 9.0,
                -1.0 / 9.0,
                -1.0 / 9.0,
                -1.0 / 9.0,
                -1.0 / 9.0,
            ],
            3,
        )
    }

    /// Creates a 3x3 Sobel edge detection kernel (horizontal edges).
    pub fn sobel_horizontal() -> Self {
        Self::new(vec![-1.0, -2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], 3)
    }

    /// Creates a 3x3 Sobel edge detection kernel (vertical edges).
    pub fn sobel_vertical() -> Self {
        Self::new(vec![-1.0, 0.0, 1.0, -2.0, 0.0, 2.0, -1.0, 0.0, 1.0], 3)
    }

    /// Creates a 3x3 Laplacian edge detection kernel.
    pub fn laplacian() -> Self {
        Self::new(vec![0.0, -1.0, 0.0, -1.0, 4.0, -1.0, 0.0, -1.0, 0.0], 3)
    }

    /// Creates a 3x3 Laplacian of Gaussian (LoG) approximation.
    pub fn laplacian_of_gaussian() -> Self {
        Self::new(vec![-1.0, -1.0, -1.0, -1.0, 8.0, -1.0, -1.0, -1.0, -1.0], 3)
    }

    /// Creates a 3x3 emboss kernel.
    pub fn emboss() -> Self {
        Self::new(vec![-2.0, -1.0, 0.0, -1.0, 1.0, 1.0, 0.0, 1.0, 2.0], 3)
    }

    /// Creates a 3x3 edge enhancement kernel.
    pub fn edge_enhance() -> Self {
        Self::new(vec![0.0, 0.0, 0.0, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0], 3)
    }

    /// Returns the kernel radius (distance from center to edge).
    pub fn radius(&self) -> usize {
        self.size / 2
    }
}

/// Applies a convolution kernel to an image.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, Kernel, convolve};
/// use rhizome_resin_color::Rgba;
///
/// // Create a simple 3x3 test image
/// let data = vec![
///     [0.5, 0.5, 0.5, 1.0]; 9
/// ];
/// let img = ImageField::from_raw(data, 3, 3);
///
/// let blurred = convolve(&img, &Kernel::box_blur());
/// ```
pub fn convolve(image: &ImageField, kernel: &Kernel) -> ImageField {
    let (width, height) = image.dimensions();
    let radius = kernel.radius() as i32;
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let mut r = 0.0;
            let mut g = 0.0;
            let mut b = 0.0;
            let mut a = 0.0;

            for ky in 0..kernel.size {
                for kx in 0..kernel.size {
                    let weight = kernel.weights[ky * kernel.size + kx];

                    // Sample with clamping at edges
                    let sx = (x as i32 + kx as i32 - radius).clamp(0, width as i32 - 1) as u32;
                    let sy = (y as i32 + ky as i32 - radius).clamp(0, height as i32 - 1) as u32;

                    let pixel = image.get_pixel(sx, sy);
                    r += pixel[0] * weight;
                    g += pixel[1] * weight;
                    b += pixel[2] * weight;
                    a += pixel[3] * weight;
                }
            }

            data.push([r, g, b, a]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Applies Sobel edge detection and returns the edge magnitude.
///
/// Combines horizontal and vertical Sobel kernels to detect edges in all directions.
pub fn detect_edges(image: &ImageField) -> ImageField {
    let horizontal = convolve(image, &Kernel::sobel_horizontal());
    let vertical = convolve(image, &Kernel::sobel_vertical());

    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let h = horizontal.get_pixel(x, y);
            let v = vertical.get_pixel(x, y);

            // Compute magnitude for each channel
            let mag_r = (h[0] * h[0] + v[0] * v[0]).sqrt();
            let mag_g = (h[1] * h[1] + v[1] * v[1]).sqrt();
            let mag_b = (h[2] * h[2] + v[2] * v[2]).sqrt();

            // Average the channels for grayscale edge output
            let mag = (mag_r + mag_g + mag_b) / 3.0;
            data.push([mag, mag, mag, 1.0]);
        }
    }

    ImageField::from_raw(data, width, height)
}

/// Applies a Gaussian blur with the specified number of passes.
///
/// Multiple passes of a small kernel approximate a larger blur radius.
pub fn blur(image: &ImageField, passes: u32) -> ImageField {
    let kernel = Kernel::gaussian_blur_3x3();
    let mut result = image.clone();

    for _ in 0..passes {
        result = convolve(&result, &kernel);
    }

    result
}

/// Sharpens an image.
pub fn sharpen(image: &ImageField) -> ImageField {
    convolve(image, &Kernel::sharpen())
}

/// Applies emboss effect to an image.
pub fn emboss(image: &ImageField) -> ImageField {
    let embossed = convolve(image, &Kernel::emboss());

    // Normalize emboss output to visible range (add 0.5 bias)
    let (width, height) = embossed.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let pixel = embossed.get_pixel(x, y);
            data.push([
                (pixel[0] + 0.5).clamp(0.0, 1.0),
                (pixel[1] + 0.5).clamp(0.0, 1.0),
                (pixel[2] + 0.5).clamp(0.0, 1.0),
                pixel[3].clamp(0.0, 1.0),
            ]);
        }
    }

    ImageField::from_raw(data, width, height)
}

// ============================================================================
// Channel operations
// ============================================================================

/// Which channel to extract or operate on.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Channel {
    /// Red channel.
    Red,
    /// Green channel.
    Green,
    /// Blue channel.
    Blue,
    /// Alpha channel.
    Alpha,
}

/// Extracts a single channel as a grayscale image.
///
/// The extracted channel is stored in all RGB channels of the output,
/// with alpha set to 1.0.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, Channel, extract_channel};
///
/// let data = vec![[1.0, 0.5, 0.25, 1.0]; 4];
/// let img = ImageField::from_raw(data, 2, 2);
///
/// let red = extract_channel(&img, Channel::Red);
/// assert_eq!(red.get_pixel(0, 0)[0], 1.0);
///
/// let green = extract_channel(&img, Channel::Green);
/// assert_eq!(green.get_pixel(0, 0)[0], 0.5);
/// ```
pub fn extract_channel(image: &ImageField, channel: Channel) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    let idx = match channel {
        Channel::Red => 0,
        Channel::Green => 1,
        Channel::Blue => 2,
        Channel::Alpha => 3,
    };

    for y in 0..height {
        for x in 0..width {
            let v = image.get_pixel(x, y)[idx];
            data.push([v, v, v, 1.0]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Splits an image into separate R, G, B, A grayscale images.
///
/// Returns a tuple of (red, green, blue, alpha) images.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, split_channels};
///
/// let data = vec![[1.0, 0.5, 0.25, 0.75]; 4];
/// let img = ImageField::from_raw(data, 2, 2);
///
/// let (r, g, b, a) = split_channels(&img);
/// assert_eq!(r.get_pixel(0, 0)[0], 1.0);
/// assert_eq!(g.get_pixel(0, 0)[0], 0.5);
/// assert_eq!(b.get_pixel(0, 0)[0], 0.25);
/// assert_eq!(a.get_pixel(0, 0)[0], 0.75);
/// ```
pub fn split_channels(image: &ImageField) -> (ImageField, ImageField, ImageField, ImageField) {
    (
        extract_channel(image, Channel::Red),
        extract_channel(image, Channel::Green),
        extract_channel(image, Channel::Blue),
        extract_channel(image, Channel::Alpha),
    )
}

/// Merges separate grayscale images into a single RGBA image.
///
/// Each input image's red channel is used as that channel's value.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, merge_channels};
///
/// let r = ImageField::from_raw(vec![[1.0, 1.0, 1.0, 1.0]; 4], 2, 2);
/// let g = ImageField::from_raw(vec![[0.5, 0.5, 0.5, 1.0]; 4], 2, 2);
/// let b = ImageField::from_raw(vec![[0.25, 0.25, 0.25, 1.0]; 4], 2, 2);
/// let a = ImageField::from_raw(vec![[1.0, 1.0, 1.0, 1.0]; 4], 2, 2);
///
/// let merged = merge_channels(&r, &g, &b, &a);
/// let pixel = merged.get_pixel(0, 0);
/// assert_eq!(pixel[0], 1.0);
/// assert_eq!(pixel[1], 0.5);
/// assert_eq!(pixel[2], 0.25);
/// ```
pub fn merge_channels(
    red: &ImageField,
    green: &ImageField,
    blue: &ImageField,
    alpha: &ImageField,
) -> ImageField {
    let (width, height) = red.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let r = red.get_pixel(x, y)[0];
            let g = green.get_pixel(x, y)[0];
            let b = blue.get_pixel(x, y)[0];
            let a = alpha.get_pixel(x, y)[0];
            data.push([r, g, b, a]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(red.wrap_mode)
        .with_filter_mode(red.filter_mode)
}

/// Replaces a single channel in an image.
///
/// The source image's red channel is used as the replacement value.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, Channel, set_channel};
///
/// let img = ImageField::from_raw(vec![[0.0, 0.0, 0.0, 1.0]; 4], 2, 2);
/// let new_red = ImageField::from_raw(vec![[1.0, 1.0, 1.0, 1.0]; 4], 2, 2);
///
/// let result = set_channel(&img, Channel::Red, &new_red);
/// assert_eq!(result.get_pixel(0, 0)[0], 1.0);
/// assert_eq!(result.get_pixel(0, 0)[1], 0.0); // Green unchanged
/// ```
pub fn set_channel(image: &ImageField, channel: Channel, source: &ImageField) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    let idx = match channel {
        Channel::Red => 0,
        Channel::Green => 1,
        Channel::Blue => 2,
        Channel::Alpha => 3,
    };

    for y in 0..height {
        for x in 0..width {
            let mut pixel = image.get_pixel(x, y);
            pixel[idx] = source.get_pixel(x, y)[0];
            data.push(pixel);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Swaps two channels in an image.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, Channel, swap_channels};
///
/// let img = ImageField::from_raw(vec![[1.0, 0.5, 0.0, 1.0]; 4], 2, 2);
/// let swapped = swap_channels(&img, Channel::Red, Channel::Blue);
///
/// assert_eq!(swapped.get_pixel(0, 0)[0], 0.0);  // Was blue
/// assert_eq!(swapped.get_pixel(0, 0)[2], 1.0);  // Was red
/// ```
pub fn swap_channels(image: &ImageField, a: Channel, b: Channel) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    let idx_a = match a {
        Channel::Red => 0,
        Channel::Green => 1,
        Channel::Blue => 2,
        Channel::Alpha => 3,
    };
    let idx_b = match b {
        Channel::Red => 0,
        Channel::Green => 1,
        Channel::Blue => 2,
        Channel::Alpha => 3,
    };

    for y in 0..height {
        for x in 0..width {
            let mut pixel = image.get_pixel(x, y);
            pixel.swap(idx_a, idx_b);
            data.push(pixel);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

// ============================================================================
// Chromatic aberration
// ============================================================================

/// Configuration for chromatic aberration effect.
#[derive(Debug, Clone, Copy)]
pub struct ChromaticAberrationConfig {
    /// Offset amount for red channel (negative = inward, positive = outward).
    pub red_offset: f32,
    /// Offset amount for green channel.
    pub green_offset: f32,
    /// Offset amount for blue channel.
    pub blue_offset: f32,
    /// Center point for radial offset (normalized coordinates, default: (0.5, 0.5)).
    pub center: (f32, f32),
}

impl Default for ChromaticAberrationConfig {
    fn default() -> Self {
        Self {
            red_offset: 0.005,
            green_offset: 0.0,
            blue_offset: -0.005,
            center: (0.5, 0.5),
        }
    }
}

impl ChromaticAberrationConfig {
    /// Creates a new config with symmetric red/blue offset.
    ///
    /// Red is pushed outward, blue inward (typical lens aberration).
    pub fn new(strength: f32) -> Self {
        Self {
            red_offset: strength,
            green_offset: 0.0,
            blue_offset: -strength,
            center: (0.5, 0.5),
        }
    }

    /// Sets the center point for radial offset.
    pub fn with_center(mut self, x: f32, y: f32) -> Self {
        self.center = (x, y);
        self
    }

    /// Sets individual channel offsets.
    pub fn with_offsets(mut self, red: f32, green: f32, blue: f32) -> Self {
        self.red_offset = red;
        self.green_offset = green;
        self.blue_offset = blue;
        self
    }
}

/// Applies chromatic aberration effect to an image.
///
/// This simulates lens chromatic aberration by offsetting each color channel
/// radially from the center point. Positive offsets push the channel outward,
/// negative offsets push inward.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, chromatic_aberration, ChromaticAberrationConfig};
///
/// let data = vec![[0.5, 0.5, 0.5, 1.0]; 16];
/// let img = ImageField::from_raw(data, 4, 4);
///
/// // Subtle chromatic aberration
/// let config = ChromaticAberrationConfig::new(0.01);
/// let result = chromatic_aberration(&img, &config);
/// ```
pub fn chromatic_aberration(image: &ImageField, config: &ChromaticAberrationConfig) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            // Normalize coordinates to [0, 1]
            let u = (x as f32 + 0.5) / width as f32;
            let v = (y as f32 + 0.5) / height as f32;

            // Vector from center to current pixel
            let dx = u - config.center.0;
            let dy = v - config.center.1;

            // Sample each channel at its offset position
            let r_u = u + dx * config.red_offset;
            let r_v = v + dy * config.red_offset;
            let r = image.sample_uv(r_u, r_v).r;

            let g_u = u + dx * config.green_offset;
            let g_v = v + dy * config.green_offset;
            let g = image.sample_uv(g_u, g_v).g;

            let b_u = u + dx * config.blue_offset;
            let b_v = v + dy * config.blue_offset;
            let b = image.sample_uv(b_u, b_v).b;

            // Alpha from original position
            let a = image.sample_uv(u, v).a;

            data.push([r, g, b, a]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Applies a quick chromatic aberration with default red/blue fringing.
///
/// # Arguments
/// * `strength` - Amount of aberration (0.01-0.05 for subtle, higher for dramatic)
pub fn chromatic_aberration_simple(image: &ImageField, strength: f32) -> ImageField {
    chromatic_aberration(image, &ChromaticAberrationConfig::new(strength))
}

// ============================================================================
// Color adjustments
// ============================================================================

/// Configuration for levels adjustment.
#[derive(Debug, Clone, Copy)]
pub struct LevelsConfig {
    /// Input black point (values below this become 0). Range: 0-1.
    pub input_black: f32,
    /// Input white point (values above this become 1). Range: 0-1.
    pub input_white: f32,
    /// Gamma correction (1.0 = linear, <1 = brighten, >1 = darken).
    pub gamma: f32,
    /// Output black point. Range: 0-1.
    pub output_black: f32,
    /// Output white point. Range: 0-1.
    pub output_white: f32,
}

impl Default for LevelsConfig {
    fn default() -> Self {
        Self {
            input_black: 0.0,
            input_white: 1.0,
            gamma: 1.0,
            output_black: 0.0,
            output_white: 1.0,
        }
    }
}

impl LevelsConfig {
    /// Creates a new levels config with only gamma adjustment.
    pub fn gamma(gamma: f32) -> Self {
        Self {
            gamma,
            ..Default::default()
        }
    }

    /// Creates a levels config that remaps black/white points.
    pub fn remap(input_black: f32, input_white: f32) -> Self {
        Self {
            input_black,
            input_white,
            ..Default::default()
        }
    }

    /// Sets the gamma value.
    pub fn with_gamma(mut self, gamma: f32) -> Self {
        self.gamma = gamma;
        self
    }

    /// Sets the output range.
    pub fn with_output(mut self, black: f32, white: f32) -> Self {
        self.output_black = black;
        self.output_white = white;
        self
    }
}

/// Applies levels adjustment to an image.
///
/// This is similar to Photoshop's Levels adjustment:
/// 1. Remap input range [input_black, input_white] to [0, 1]
/// 2. Apply gamma correction
/// 3. Remap [0, 1] to [output_black, output_white]
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, adjust_levels, LevelsConfig};
///
/// let data = vec![[0.3, 0.5, 0.7, 1.0]; 4];
/// let img = ImageField::from_raw(data, 2, 2);
///
/// // Increase contrast by pulling in black/white points
/// let config = LevelsConfig::remap(0.2, 0.8);
/// let result = adjust_levels(&img, &config);
/// ```
pub fn adjust_levels(image: &ImageField, config: &LevelsConfig) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    let input_range = (config.input_white - config.input_black).max(0.001);
    let output_range = config.output_white - config.output_black;
    // Gamma < 1 brightens (raises values), gamma > 1 darkens (lowers values)
    let gamma = config.gamma.max(0.001);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);

            let adjust = |v: f32| -> f32 {
                // Remap input
                let normalized = ((v - config.input_black) / input_range).clamp(0.0, 1.0);
                // Apply gamma (gamma < 1 brightens, gamma > 1 darkens)
                let gamma_corrected = normalized.powf(gamma);
                // Remap output
                (gamma_corrected * output_range + config.output_black).clamp(0.0, 1.0)
            };

            data.push([
                adjust(pixel[0]),
                adjust(pixel[1]),
                adjust(pixel[2]),
                pixel[3],
            ]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Adjusts brightness and contrast of an image.
///
/// # Arguments
/// * `brightness` - Brightness adjustment (-1 to 1, 0 = no change)
/// * `contrast` - Contrast adjustment (-1 to 1, 0 = no change)
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, adjust_brightness_contrast};
///
/// let data = vec![[0.5, 0.5, 0.5, 1.0]; 4];
/// let img = ImageField::from_raw(data, 2, 2);
///
/// let result = adjust_brightness_contrast(&img, 0.1, 0.2);
/// ```
pub fn adjust_brightness_contrast(
    image: &ImageField,
    brightness: f32,
    contrast: f32,
) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    // Convert contrast to multiplier: 0 = 1x, 1 = 2x, -1 = 0x
    let contrast_factor = (1.0 + contrast).max(0.0);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);

            let adjust = |v: f32| -> f32 {
                // Apply contrast around midpoint, then brightness
                let contrasted = (v - 0.5) * contrast_factor + 0.5;
                (contrasted + brightness).clamp(0.0, 1.0)
            };

            data.push([
                adjust(pixel[0]),
                adjust(pixel[1]),
                adjust(pixel[2]),
                pixel[3],
            ]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Configuration for HSL adjustments.
#[derive(Debug, Clone, Copy, Default)]
pub struct HslAdjustment {
    /// Hue shift (-0.5 to 0.5, wraps around the color wheel).
    pub hue_shift: f32,
    /// Saturation adjustment (-1 = grayscale, 0 = no change, 1 = double saturation).
    pub saturation: f32,
    /// Lightness adjustment (-1 = black, 0 = no change, 1 = white).
    pub lightness: f32,
}

impl HslAdjustment {
    /// Creates a hue shift adjustment.
    pub fn hue(shift: f32) -> Self {
        Self {
            hue_shift: shift,
            saturation: 0.0,
            lightness: 0.0,
        }
    }

    /// Creates a saturation adjustment.
    pub fn saturation(amount: f32) -> Self {
        Self {
            hue_shift: 0.0,
            saturation: amount,
            lightness: 0.0,
        }
    }

    /// Creates a lightness adjustment.
    pub fn lightness(amount: f32) -> Self {
        Self {
            hue_shift: 0.0,
            saturation: 0.0,
            lightness: amount,
        }
    }

    /// Sets the hue shift.
    pub fn with_hue(mut self, shift: f32) -> Self {
        self.hue_shift = shift;
        self
    }

    /// Sets the saturation adjustment.
    pub fn with_saturation(mut self, amount: f32) -> Self {
        self.saturation = amount;
        self
    }

    /// Sets the lightness adjustment.
    pub fn with_lightness(mut self, amount: f32) -> Self {
        self.lightness = amount;
        self
    }
}

/// Adjusts hue, saturation, and lightness of an image.
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, adjust_hsl, HslAdjustment};
///
/// let data = vec![[1.0, 0.5, 0.0, 1.0]; 4]; // Orange
/// let img = ImageField::from_raw(data, 2, 2);
///
/// // Shift hue by 180 degrees (complement)
/// let result = adjust_hsl(&img, &HslAdjustment::hue(0.5));
/// ```
pub fn adjust_hsl(image: &ImageField, adjustment: &HslAdjustment) -> ImageField {
    use rhizome_resin_color::{Hsl, LinearRgb};

    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);

            // Convert to HSL
            let rgb = LinearRgb::new(pixel[0], pixel[1], pixel[2]);
            let hsl = rgb.to_hsl();

            // Apply adjustments
            let new_h = (hsl.h + adjustment.hue_shift).rem_euclid(1.0);
            let new_s = (hsl.s * (1.0 + adjustment.saturation)).clamp(0.0, 1.0);
            let new_l = (hsl.l + adjustment.lightness).clamp(0.0, 1.0);

            // Convert back
            let new_rgb = Hsl::new(new_h, new_s, new_l).to_rgb();

            data.push([new_rgb.r, new_rgb.g, new_rgb.b, pixel[3]]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Converts an image to grayscale using luminance.
///
/// Uses ITU-R BT.709 coefficients: 0.2126 R + 0.7152 G + 0.0722 B
pub fn grayscale(image: &ImageField) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);
            let lum = 0.2126 * pixel[0] + 0.7152 * pixel[1] + 0.0722 * pixel[2];
            data.push([lum, lum, lum, pixel[3]]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Inverts the colors of an image.
///
/// Each RGB channel is inverted (1 - value). Alpha is preserved.
pub fn invert(image: &ImageField) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);
            data.push([1.0 - pixel[0], 1.0 - pixel[1], 1.0 - pixel[2], pixel[3]]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Applies a posterization effect, reducing the number of color levels.
///
/// # Arguments
/// * `levels` - Number of levels per channel (2-256, typically 2-8 for visible effect)
pub fn posterize(image: &ImageField, levels: u32) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    let levels = levels.clamp(2, 256) as f32;
    let factor = levels - 1.0;

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);

            let quantize = |v: f32| ((v * factor).round() / factor).clamp(0.0, 1.0);

            data.push([
                quantize(pixel[0]),
                quantize(pixel[1]),
                quantize(pixel[2]),
                pixel[3],
            ]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

/// Applies a threshold effect, converting to black and white.
///
/// Pixels with luminance above the threshold become white, below become black.
pub fn threshold(image: &ImageField, threshold: f32) -> ImageField {
    let (width, height) = image.dimensions();
    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            let pixel = image.get_pixel(x, y);
            let lum = 0.2126 * pixel[0] + 0.7152 * pixel[1] + 0.0722 * pixel[2];
            let v = if lum > threshold { 1.0 } else { 0.0 };
            data.push([v, v, v, pixel[3]]);
        }
    }

    ImageField::from_raw(data, width, height)
        .with_wrap_mode(image.wrap_mode)
        .with_filter_mode(image.filter_mode)
}

// ============================================================================
// Normal map generation
// ============================================================================

/// Generates a normal map from a heightfield/grayscale image.
///
/// Uses Sobel operators to compute gradients, then constructs normal vectors.
/// The output is an RGB image where:
/// - R = X component of normal (mapped to 0-1)
/// - G = Y component of normal (mapped to 0-1)
/// - B = Z component of normal (mapped to 0-1)
///
/// # Arguments
/// * `heightfield` - Grayscale image where brightness = height
/// * `strength` - How pronounced the normals should be (typically 1.0-10.0)
///
/// # Example
///
/// ```
/// use rhizome_resin_image::{ImageField, heightfield_to_normal_map};
///
/// // Create a simple gradient heightfield
/// let data: Vec<_> = (0..16).map(|i| {
///     let v = (i % 4) as f32 / 3.0;
///     [v, v, v, 1.0]
/// }).collect();
/// let heightfield = ImageField::from_raw(data, 4, 4);
///
/// let normal_map = heightfield_to_normal_map(&heightfield, 2.0);
/// ```
pub fn heightfield_to_normal_map(heightfield: &ImageField, strength: f32) -> ImageField {
    let (width, height) = heightfield.dimensions();

    // Compute gradients using Sobel operators
    let dx = convolve(heightfield, &Kernel::sobel_vertical());
    let dy = convolve(heightfield, &Kernel::sobel_horizontal());

    let mut data = Vec::with_capacity((width * height) as usize);

    for y in 0..height {
        for x in 0..width {
            // Get gradient values (use red channel for grayscale)
            let gx = dx.get_pixel(x, y)[0] * strength;
            let gy = dy.get_pixel(x, y)[0] * strength;

            // Construct normal vector: (-gx, -gy, 1) and normalize
            let len = (gx * gx + gy * gy + 1.0).sqrt();
            let nx = -gx / len;
            let ny = -gy / len;
            let nz = 1.0 / len;

            // Map from [-1, 1] to [0, 1] for storage
            let r = nx * 0.5 + 0.5;
            let g = ny * 0.5 + 0.5;
            let b = nz * 0.5 + 0.5;

            data.push([r, g, b, 1.0]);
        }
    }

    ImageField::from_raw(data, width, height)
}

/// Generates a normal map from a Field<Vec2, f32> heightfield.
///
/// This samples the field at the specified resolution and generates normals.
///
/// # Arguments
/// * `field` - A 2D scalar field representing height
/// * `config` - Bake configuration for resolution
/// * `strength` - Normal map strength
pub fn field_to_normal_map<F: Field<Vec2, f32>>(
    field: &F,
    config: &BakeConfig,
    strength: f32,
) -> ImageField {
    let ctx = EvalContext::new();

    // First bake the heightfield
    let heightfield = bake_scalar(field, config, &ctx);

    // Then convert to normal map
    heightfield_to_normal_map(&heightfield, strength)
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_image() -> ImageField {
        // 2x2 test image
        let data = vec![
            [1.0, 0.0, 0.0, 1.0], // Red
            [0.0, 1.0, 0.0, 1.0], // Green
            [0.0, 0.0, 1.0, 1.0], // Blue
            [1.0, 1.0, 1.0, 1.0], // White
        ];
        ImageField::from_raw(data, 2, 2)
    }

    #[test]
    fn test_nearest_sampling() {
        let img = create_test_image().with_filter_mode(FilterMode::Nearest);

        let tl = img.sample_uv(0.0, 0.0);
        assert!((tl.r - 1.0).abs() < 0.001);

        let tr = img.sample_uv(0.99, 0.0);
        assert!((tr.g - 1.0).abs() < 0.001);
    }

    #[test]
    fn test_bilinear_sampling() {
        let img = create_test_image().with_filter_mode(FilterMode::Bilinear);

        let center = img.sample_uv(0.5, 0.5);
        assert!(center.r > 0.1 && center.r < 0.9);
    }

    #[test]
    fn test_field_trait() {
        let img = create_test_image().with_filter_mode(FilterMode::Nearest);
        let ctx = EvalContext::new();

        let color: Rgba = img.sample(Vec2::new(0.0, 0.0), &ctx);
        assert!(color.r > 0.5);
    }

    // Texture baking tests

    /// A simple field that returns UV coordinates as grayscale.
    struct GradientField;

    impl Field<Vec2, f32> for GradientField {
        fn sample(&self, input: Vec2, _ctx: &EvalContext) -> f32 {
            (input.x + input.y) / 2.0
        }
    }

    /// A simple field that returns UV coordinates as color.
    struct ColorGradientField;

    impl Field<Vec2, Rgba> for ColorGradientField {
        fn sample(&self, input: Vec2, _ctx: &EvalContext) -> Rgba {
            Rgba::new(input.x, input.y, 0.5, 1.0)
        }
    }

    impl Field<Vec2, Vec4> for ColorGradientField {
        fn sample(&self, input: Vec2, _ctx: &EvalContext) -> Vec4 {
            Vec4::new(input.x, input.y, 0.5, 1.0)
        }
    }

    #[test]
    fn test_bake_scalar() {
        let field = GradientField;
        let config = BakeConfig::new(4, 4);
        let ctx = EvalContext::new();

        let image = bake_scalar(&field, &config, &ctx);
        assert_eq!(image.dimensions(), (4, 4));

        // Top-left should be darker, bottom-right should be brighter
        let tl = image.sample_uv(0.125, 0.125); // First pixel center
        let br = image.sample_uv(0.875, 0.875); // Last pixel center
        assert!(tl.r < br.r);
    }

    #[test]
    fn test_bake_scalar_with_aa() {
        let field = GradientField;
        let config = BakeConfig::new(4, 4).with_samples(4);
        let ctx = EvalContext::new();

        let image = bake_scalar(&field, &config, &ctx);
        assert_eq!(image.dimensions(), (4, 4));
    }

    #[test]
    fn test_bake_rgba() {
        let field = ColorGradientField;
        let config = BakeConfig::new(4, 4);
        let ctx = EvalContext::new();

        let image = bake_rgba(&field, &config, &ctx);
        assert_eq!(image.dimensions(), (4, 4));

        // Check that colors vary as expected
        let tl = image.sample_uv(0.125, 0.125);
        let br = image.sample_uv(0.875, 0.875);
        assert!(tl.r < br.r); // Red increases with X
        assert!(tl.g < br.g); // Green increases with Y
    }

    #[test]
    fn test_bake_vec4() {
        let field = ColorGradientField;
        let config = BakeConfig::new(4, 4);
        let ctx = EvalContext::new();

        let image = bake_vec4(&field, &config, &ctx);
        assert_eq!(image.dimensions(), (4, 4));
    }

    #[test]
    fn test_bake_config_builder() {
        let config = BakeConfig::new(512, 256).with_samples(16);
        assert_eq!(config.width, 512);
        assert_eq!(config.height, 256);
        assert_eq!(config.samples, 16);
    }

    #[test]
    fn test_bake_config_default() {
        let config = BakeConfig::default();
        assert_eq!(config.width, 256);
        assert_eq!(config.height, 256);
        assert_eq!(config.samples, 1);
    }

    // Animation tests

    /// A time-varying color field for animation testing.
    struct AnimatedField;

    impl Field<glam::Vec3, Rgba> for AnimatedField {
        fn sample(&self, input: glam::Vec3, _ctx: &EvalContext) -> Rgba {
            // Color changes with time (z coordinate)
            let r = (input.x + input.z) % 1.0;
            let g = input.y;
            let b = input.z;
            Rgba::new(r, g, b, 1.0)
        }
    }

    /// A time-varying scalar field.
    struct AnimatedScalarField;

    impl Field<glam::Vec3, f32> for AnimatedScalarField {
        fn sample(&self, input: glam::Vec3, _ctx: &EvalContext) -> f32 {
            // Value oscillates with time
            ((input.x + input.z * 10.0) * std::f32::consts::PI).sin() * 0.5 + 0.5
        }
    }

    #[test]
    fn test_animation_config() {
        let config = AnimationConfig::new(128, 128, 30).with_fps(60.0);
        assert_eq!(config.width, 128);
        assert_eq!(config.height, 128);
        assert_eq!(config.num_frames, 30);
        assert!((config.frame_duration - 1.0 / 60.0).abs() < 0.0001);
        assert!((config.duration() - 0.5).abs() < 0.001);
    }

    #[test]
    fn test_render_animation() {
        let field = AnimatedField;
        let config = AnimationConfig::new(4, 4, 5).with_fps(10.0);

        let frames = render_animation(&field, &config);
        assert_eq!(frames.len(), 5);

        // Each frame should have the correct dimensions
        for frame in &frames {
            assert_eq!(frame.dimensions(), (4, 4));
        }

        // Frames should be different (animation is happening)
        let first = frames[0].sample_uv(0.5, 0.5);
        let last = frames[4].sample_uv(0.5, 0.5);
        // Blue channel changes with time
        assert!((first.b - last.b).abs() > 0.001);
    }

    #[test]
    fn test_render_animation_scalar() {
        let field = AnimatedScalarField;
        let config = AnimationConfig::new(4, 4, 3);

        let frames = render_animation_scalar(&field, &config);
        assert_eq!(frames.len(), 3);
    }

    // Convolution filter tests

    fn create_convolution_test_image() -> ImageField {
        // 5x5 image with a bright center for testing filters
        let mut data = vec![[0.0, 0.0, 0.0, 1.0]; 25];
        data[12] = [1.0, 1.0, 1.0, 1.0]; // Center pixel is white
        ImageField::from_raw(data, 5, 5)
    }

    #[test]
    fn test_kernel_identity() {
        let img = create_convolution_test_image();
        let result = convolve(&img, &Kernel::identity());

        // Identity kernel should not change the image
        let center = result.get_pixel(2, 2);
        assert!((center[0] - 1.0).abs() < 0.001);

        let corner = result.get_pixel(0, 0);
        assert!(corner[0].abs() < 0.001);
    }

    #[test]
    fn test_kernel_box_blur() {
        let img = create_convolution_test_image();
        let result = convolve(&img, &Kernel::box_blur());

        // Box blur should spread the center pixel's value
        let center = result.get_pixel(2, 2);
        assert!(center[0] > 0.0 && center[0] < 1.0);

        // Neighbors should also have some value now
        let neighbor = result.get_pixel(2, 1);
        assert!(neighbor[0] > 0.0);
    }

    #[test]
    fn test_kernel_gaussian_blur() {
        let img = create_convolution_test_image();
        let result = convolve(&img, &Kernel::gaussian_blur_3x3());

        // Gaussian blur should smooth the image
        let center = result.get_pixel(2, 2);
        assert!(center[0] > 0.0 && center[0] < 1.0);
    }

    #[test]
    fn test_kernel_sharpen() {
        // Create an image with gradual variation
        let data: Vec<_> = (0..25)
            .map(|i| {
                let v = (i as f32) / 24.0;
                [v, v, v, 1.0]
            })
            .collect();
        let img = ImageField::from_raw(data, 5, 5);
        let result = convolve(&img, &Kernel::sharpen());

        // Sharpening should increase contrast at edges
        assert_eq!(result.dimensions(), (5, 5));
    }

    #[test]
    fn test_kernel_sobel() {
        // Create an image with a vertical edge
        let mut data = vec![[0.0, 0.0, 0.0, 1.0]; 25];
        for y in 0..5 {
            data[y * 5 + 3] = [1.0, 1.0, 1.0, 1.0];
            data[y * 5 + 4] = [1.0, 1.0, 1.0, 1.0];
        }
        let img = ImageField::from_raw(data, 5, 5);

        let result = convolve(&img, &Kernel::sobel_vertical());

        // Vertical Sobel should detect the edge
        let edge_pixel = result.get_pixel(2, 2);
        assert!(edge_pixel[0].abs() > 0.1);
    }

    #[test]
    fn test_detect_edges() {
        let img = create_convolution_test_image();
        let edges = detect_edges(&img);

        assert_eq!(edges.dimensions(), (5, 5));
        // Edge detection should produce non-negative values
        let pixel = edges.get_pixel(2, 2);
        assert!(pixel[0] >= 0.0);
    }

    #[test]
    fn test_blur_function() {
        let img = create_convolution_test_image();
        let blurred = blur(&img, 2);

        // Multiple blur passes should spread the bright pixel more
        let center = blurred.get_pixel(2, 2);
        assert!(center[0] > 0.0 && center[0] < 0.5);
    }

    #[test]
    fn test_sharpen_function() {
        let img = create_convolution_test_image();
        let sharpened = sharpen(&img);

        assert_eq!(sharpened.dimensions(), (5, 5));
    }

    #[test]
    fn test_emboss_function() {
        let img = create_convolution_test_image();
        let embossed = emboss(&img);

        assert_eq!(embossed.dimensions(), (5, 5));
        // Emboss output should be normalized to visible range
        let pixel = embossed.get_pixel(2, 2);
        assert!(pixel[0] >= 0.0 && pixel[0] <= 1.0);
    }

    #[test]
    fn test_kernel_5x5() {
        let img = create_convolution_test_image();
        let result = convolve(&img, &Kernel::gaussian_blur_5x5());

        // 5x5 kernel should still work
        assert_eq!(result.dimensions(), (5, 5));
        let center = result.get_pixel(2, 2);
        assert!(center[0] > 0.0);
    }

    // Normal map tests

    #[test]
    fn test_heightfield_to_normal_map_flat() {
        // Flat heightfield should produce normals pointing straight up (0.5, 0.5, 1.0)
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 9];
        let heightfield = ImageField::from_raw(data, 3, 3);

        let normal_map = heightfield_to_normal_map(&heightfield, 1.0);
        assert_eq!(normal_map.dimensions(), (3, 3));

        // Center pixel should have normal pointing up (encoded as ~0.5, ~0.5, ~1.0)
        let center = normal_map.get_pixel(1, 1);
        assert!((center[0] - 0.5).abs() < 0.1); // X ~= 0
        assert!((center[1] - 0.5).abs() < 0.1); // Y ~= 0
        assert!(center[2] > 0.9); // Z ~= 1 (pointing up)
    }

    #[test]
    fn test_heightfield_to_normal_map_slope() {
        // Create a slope (gradient from left to right)
        let data: Vec<_> = (0..9)
            .map(|i| {
                let v = (i % 3) as f32 / 2.0;
                [v, v, v, 1.0]
            })
            .collect();
        let heightfield = ImageField::from_raw(data, 3, 3);

        let normal_map = heightfield_to_normal_map(&heightfield, 2.0);
        assert_eq!(normal_map.dimensions(), (3, 3));

        // Normals should tilt in the X direction
        let center = normal_map.get_pixel(1, 1);
        // X component should be non-zero due to slope
        assert!(center[2] > 0.5); // Z still positive (pointing somewhat up)
    }

    #[test]
    fn test_heightfield_to_normal_map_strength() {
        // Same heightfield with different strengths
        let data: Vec<_> = (0..9)
            .map(|i| {
                let v = (i % 3) as f32 / 2.0;
                [v, v, v, 1.0]
            })
            .collect();
        let heightfield = ImageField::from_raw(data, 3, 3);

        let weak = heightfield_to_normal_map(&heightfield, 1.0);
        let strong = heightfield_to_normal_map(&heightfield, 5.0);

        // Stronger normals should have lower Z (more tilted)
        let weak_z = weak.get_pixel(1, 1)[2];
        let strong_z = strong.get_pixel(1, 1)[2];
        assert!(weak_z >= strong_z);
    }

    #[test]
    fn test_field_to_normal_map() {
        // Use a simple gradient field
        let config = BakeConfig::new(4, 4);
        let normal_map = field_to_normal_map(&GradientField, &config, 2.0);

        assert_eq!(normal_map.dimensions(), (4, 4));
        // All pixels should have valid normal values in [0, 1]
        for y in 0..4 {
            for x in 0..4 {
                let pixel = normal_map.get_pixel(x, y);
                assert!(pixel[0] >= 0.0 && pixel[0] <= 1.0);
                assert!(pixel[1] >= 0.0 && pixel[1] <= 1.0);
                assert!(pixel[2] >= 0.0 && pixel[2] <= 1.0);
            }
        }
    }

    // Channel operation tests

    #[test]
    fn test_extract_channel() {
        let data = vec![[1.0, 0.5, 0.25, 0.75]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        let red = extract_channel(&img, Channel::Red);
        assert_eq!(red.get_pixel(0, 0)[0], 1.0);
        assert_eq!(red.get_pixel(0, 0)[1], 1.0); // Grayscale - all channels same

        let green = extract_channel(&img, Channel::Green);
        assert_eq!(green.get_pixel(0, 0)[0], 0.5);

        let blue = extract_channel(&img, Channel::Blue);
        assert_eq!(blue.get_pixel(0, 0)[0], 0.25);

        let alpha = extract_channel(&img, Channel::Alpha);
        assert_eq!(alpha.get_pixel(0, 0)[0], 0.75);
    }

    #[test]
    fn test_split_channels() {
        let data = vec![[1.0, 0.5, 0.25, 0.75]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        let (r, g, b, a) = split_channels(&img);

        assert_eq!(r.get_pixel(0, 0)[0], 1.0);
        assert_eq!(g.get_pixel(0, 0)[0], 0.5);
        assert_eq!(b.get_pixel(0, 0)[0], 0.25);
        assert_eq!(a.get_pixel(0, 0)[0], 0.75);
    }

    #[test]
    fn test_merge_channels() {
        let r = ImageField::from_raw(vec![[1.0, 1.0, 1.0, 1.0]; 4], 2, 2);
        let g = ImageField::from_raw(vec![[0.5, 0.5, 0.5, 1.0]; 4], 2, 2);
        let b = ImageField::from_raw(vec![[0.25, 0.25, 0.25, 1.0]; 4], 2, 2);
        let a = ImageField::from_raw(vec![[0.75, 0.75, 0.75, 1.0]; 4], 2, 2);

        let merged = merge_channels(&r, &g, &b, &a);
        let pixel = merged.get_pixel(0, 0);

        assert_eq!(pixel[0], 1.0);
        assert_eq!(pixel[1], 0.5);
        assert_eq!(pixel[2], 0.25);
        assert_eq!(pixel[3], 0.75);
    }

    #[test]
    fn test_set_channel() {
        let img = ImageField::from_raw(vec![[0.0, 0.0, 0.0, 1.0]; 4], 2, 2);
        let new_val = ImageField::from_raw(vec![[0.8, 0.8, 0.8, 1.0]; 4], 2, 2);

        let result = set_channel(&img, Channel::Red, &new_val);
        assert_eq!(result.get_pixel(0, 0)[0], 0.8);
        assert_eq!(result.get_pixel(0, 0)[1], 0.0); // Unchanged

        let result = set_channel(&img, Channel::Green, &new_val);
        assert_eq!(result.get_pixel(0, 0)[1], 0.8);
        assert_eq!(result.get_pixel(0, 0)[0], 0.0); // Unchanged
    }

    #[test]
    fn test_swap_channels() {
        let img = ImageField::from_raw(vec![[1.0, 0.5, 0.0, 1.0]; 4], 2, 2);
        let swapped = swap_channels(&img, Channel::Red, Channel::Blue);

        assert_eq!(swapped.get_pixel(0, 0)[0], 0.0); // Was blue
        assert_eq!(swapped.get_pixel(0, 0)[1], 0.5); // Unchanged
        assert_eq!(swapped.get_pixel(0, 0)[2], 1.0); // Was red
    }

    #[test]
    fn test_split_merge_roundtrip() {
        let data = vec![
            [0.1, 0.2, 0.3, 0.4],
            [0.5, 0.6, 0.7, 0.8],
            [0.9, 0.8, 0.7, 0.6],
            [0.3, 0.4, 0.5, 0.6],
        ];
        let img = ImageField::from_raw(data.clone(), 2, 2);

        let (r, g, b, a) = split_channels(&img);
        let merged = merge_channels(&r, &g, &b, &a);

        for (i, original) in data.iter().enumerate() {
            let x = (i % 2) as u32;
            let y = (i / 2) as u32;
            let pixel = merged.get_pixel(x, y);
            assert!((pixel[0] - original[0]).abs() < 0.001);
            assert!((pixel[1] - original[1]).abs() < 0.001);
            assert!((pixel[2] - original[2]).abs() < 0.001);
            assert!((pixel[3] - original[3]).abs() < 0.001);
        }
    }

    // Chromatic aberration tests

    #[test]
    fn test_chromatic_aberration_config() {
        let config = ChromaticAberrationConfig::new(0.02);
        assert_eq!(config.red_offset, 0.02);
        assert_eq!(config.green_offset, 0.0);
        assert_eq!(config.blue_offset, -0.02);
        assert_eq!(config.center, (0.5, 0.5));
    }

    #[test]
    fn test_chromatic_aberration_config_builder() {
        let config = ChromaticAberrationConfig::new(0.01)
            .with_center(0.3, 0.7)
            .with_offsets(0.02, 0.01, -0.01);

        assert_eq!(config.center, (0.3, 0.7));
        assert_eq!(config.red_offset, 0.02);
        assert_eq!(config.green_offset, 0.01);
        assert_eq!(config.blue_offset, -0.01);
    }

    #[test]
    fn test_chromatic_aberration_preserves_dimensions() {
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 25];
        let img = ImageField::from_raw(data, 5, 5);

        let result = chromatic_aberration(&img, &ChromaticAberrationConfig::new(0.1));
        assert_eq!(result.dimensions(), (5, 5));
    }

    #[test]
    fn test_chromatic_aberration_zero_strength() {
        // Zero strength should leave image unchanged
        let data = vec![
            [1.0, 0.0, 0.0, 1.0],
            [0.0, 1.0, 0.0, 1.0],
            [0.0, 0.0, 1.0, 1.0],
            [1.0, 1.0, 1.0, 1.0],
        ];
        let img = ImageField::from_raw(data.clone(), 2, 2);

        let config = ChromaticAberrationConfig::new(0.0);
        let result = chromatic_aberration(&img, &config);

        for (i, original) in data.iter().enumerate() {
            let x = (i % 2) as u32;
            let y = (i / 2) as u32;
            let pixel = result.get_pixel(x, y);
            assert!((pixel[0] - original[0]).abs() < 0.01);
            assert!((pixel[1] - original[1]).abs() < 0.01);
            assert!((pixel[2] - original[2]).abs() < 0.01);
        }
    }

    #[test]
    fn test_chromatic_aberration_simple() {
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 16];
        let img = ImageField::from_raw(data, 4, 4);

        let result = chromatic_aberration_simple(&img, 0.05);
        assert_eq!(result.dimensions(), (4, 4));
    }

    #[test]
    fn test_chromatic_aberration_center_unchanged() {
        // At the center, all channels should sample from nearly the same location
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 9];
        let img = ImageField::from_raw(data, 3, 3);

        let result = chromatic_aberration(&img, &ChromaticAberrationConfig::new(0.1));

        // Center pixel should be very similar to original
        let center = result.get_pixel(1, 1);
        assert!((center[0] - 0.5).abs() < 0.1);
        assert!((center[1] - 0.5).abs() < 0.1);
        assert!((center[2] - 0.5).abs() < 0.1);
    }

    // Color adjustment tests

    #[test]
    fn test_levels_default() {
        let data = vec![[0.3, 0.5, 0.7, 1.0]; 4];
        let img = ImageField::from_raw(data.clone(), 2, 2);

        // Default config should not change the image
        let result = adjust_levels(&img, &LevelsConfig::default());
        let pixel = result.get_pixel(0, 0);
        assert!((pixel[0] - 0.3).abs() < 0.01);
        assert!((pixel[1] - 0.5).abs() < 0.01);
        assert!((pixel[2] - 0.7).abs() < 0.01);
    }

    #[test]
    fn test_levels_gamma() {
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        // Gamma < 1 brightens
        let brightened = adjust_levels(&img, &LevelsConfig::gamma(0.5));
        assert!(brightened.get_pixel(0, 0)[0] > 0.5);

        // Gamma > 1 darkens
        let darkened = adjust_levels(&img, &LevelsConfig::gamma(2.0));
        assert!(darkened.get_pixel(0, 0)[0] < 0.5);
    }

    #[test]
    fn test_levels_remap() {
        let data = vec![[0.3, 0.5, 0.7, 1.0]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        // Remap [0.2, 0.8] to [0, 1] - should increase contrast
        let config = LevelsConfig::remap(0.2, 0.8);
        let result = adjust_levels(&img, &config);

        // 0.3 should map to ~0.167 (below black point)
        // 0.5 should map to ~0.5 (middle)
        // 0.7 should map to ~0.833 (above black point)
        let pixel = result.get_pixel(0, 0);
        assert!(pixel[0] < 0.3); // Darker than original
        assert!((pixel[1] - 0.5).abs() < 0.01); // About the same
        assert!(pixel[2] > 0.7); // Brighter than original
    }

    #[test]
    fn test_brightness_contrast() {
        let data = vec![[0.5, 0.5, 0.5, 1.0]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        // Brightness only
        let brighter = adjust_brightness_contrast(&img, 0.2, 0.0);
        assert!((brighter.get_pixel(0, 0)[0] - 0.7).abs() < 0.01);

        // Contrast only - midpoint unchanged
        let contrasted = adjust_brightness_contrast(&img, 0.0, 0.5);
        assert!((contrasted.get_pixel(0, 0)[0] - 0.5).abs() < 0.01);
    }

    #[test]
    fn test_brightness_contrast_edges() {
        let data = vec![[0.0, 0.25, 0.75, 1.0]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        // High contrast should push values toward 0 and 1
        let contrasted = adjust_brightness_contrast(&img, 0.0, 0.5);
        let pixel = contrasted.get_pixel(0, 0);
        assert!(pixel[0] < 0.0 + 0.01); // Should be clamped to 0
        assert!(pixel[1] < 0.25); // Should be pushed darker
        assert!(pixel[2] > 0.75); // Should be pushed brighter
        assert!(pixel[3] > 0.99); // Should be clamped to 1
    }

    #[test]
    fn test_hsl_adjustment_hue() {
        let data = vec![[1.0, 0.0, 0.0, 1.0]; 4]; // Pure red
        let img = ImageField::from_raw(data, 2, 2);

        // Shift hue by 1/3 (120 degrees) - red -> green
        let result = adjust_hsl(&img, &HslAdjustment::hue(1.0 / 3.0));
        let pixel = result.get_pixel(0, 0);
        assert!(pixel[1] > pixel[0]); // Green should dominate
        assert!(pixel[1] > pixel[2]); // Green > blue
    }

    #[test]
    fn test_hsl_adjustment_saturation() {
        let data = vec![[1.0, 0.5, 0.5, 1.0]; 4]; // Pinkish
        let img = ImageField::from_raw(data, 2, 2);

        // Desaturate
        let desaturated = adjust_hsl(&img, &HslAdjustment::saturation(-0.5));
        let pixel = desaturated.get_pixel(0, 0);
        // Should be more gray - channels closer together
        let range = pixel[0].max(pixel[1]).max(pixel[2]) - pixel[0].min(pixel[1]).min(pixel[2]);
        assert!(range < 0.5); // Range should be reduced
    }

    #[test]
    fn test_grayscale() {
        let data = vec![[1.0, 0.0, 0.0, 1.0]; 4]; // Red
        let img = ImageField::from_raw(data, 2, 2);

        let gray = grayscale(&img);
        let pixel = gray.get_pixel(0, 0);

        // All channels should be equal
        assert!((pixel[0] - pixel[1]).abs() < 0.001);
        assert!((pixel[1] - pixel[2]).abs() < 0.001);

        // Should be approximately 0.2126 (red luminance coefficient)
        assert!((pixel[0] - 0.2126).abs() < 0.01);
    }

    #[test]
    fn test_invert() {
        let data = vec![[0.2, 0.5, 0.8, 0.9]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        let inverted = invert(&img);
        let pixel = inverted.get_pixel(0, 0);

        assert!((pixel[0] - 0.8).abs() < 0.001);
        assert!((pixel[1] - 0.5).abs() < 0.001);
        assert!((pixel[2] - 0.2).abs() < 0.001);
        assert!((pixel[3] - 0.9).abs() < 0.001); // Alpha unchanged
    }

    #[test]
    fn test_posterize() {
        let data = vec![[0.33, 0.66, 0.99, 1.0]; 4];
        let img = ImageField::from_raw(data, 2, 2);

        // 2 levels = only 0 or 1
        let posterized = posterize(&img, 2);
        let pixel = posterized.get_pixel(0, 0);
        assert!(pixel[0] == 0.0 || pixel[0] == 1.0);
        assert!(pixel[1] == 0.0 || pixel[1] == 1.0);
        assert!(pixel[2] == 0.0 || pixel[2] == 1.0);
    }

    #[test]
    fn test_threshold() {
        let data = vec![
            [0.3, 0.3, 0.3, 1.0],
            [0.7, 0.7, 0.7, 1.0],
            [0.5, 0.5, 0.5, 1.0],
            [0.5, 0.5, 0.5, 1.0],
        ];
        let img = ImageField::from_raw(data, 2, 2);

        let result = threshold(&img, 0.5);

        // 0.3 luminance < 0.5 -> black
        assert!(result.get_pixel(0, 0)[0] < 0.01);
        // 0.7 luminance > 0.5 -> white
        assert!(result.get_pixel(1, 0)[0] > 0.99);
    }
}
